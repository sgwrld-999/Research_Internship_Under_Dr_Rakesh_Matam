2025-09-11 14:15:16,026 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:15:16,026 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 13 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,373

Training Setup:
  - Learning rate: 0.001
  - Batch size: 32
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2

Monitoring:
  - Metrics: accuracy, precision, recall
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:15:16,026 - __main__ - ERROR - Training pipeline failed: 'str' object has no attribute 'exists'
2025-09-11 14:15:16,026 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 584, in main
    if not data_path.exists():
           ^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'exists'
2025-09-11 14:16:17,310 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:16:17,310 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 13 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,373

Training Setup:
  - Learning rate: 0.001
  - Batch size: 32
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2

Monitoring:
  - Metrics: accuracy, precision, recall
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:16:17,310 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 14:16:18,293 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 14:16:18,293 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 14:16:18,293 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 14:16:18,293 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 14:16:18,331 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 14:16:18,331 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 14:16:18,331 - __main__ - ERROR - Training pipeline failed: Feature dimension mismatch: expected 13, got 14. Please update config.input_dim or check your data.
2025-09-11 14:16:18,331 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 591, in main
    X, y = processor.prepare_preprocessed_data(raw_data)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 274, in prepare_preprocessed_data
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Feature dimension mismatch: expected 13, got 14. Please update config.input_dim or check your data.
2025-09-11 14:17:28,649 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:17:28,649 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 14 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,501

Training Setup:
  - Learning rate: 0.001
  - Batch size: 32
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2

Monitoring:
  - Metrics: accuracy, precision, recall
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:17:28,649 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 14:17:29,535 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 14:17:29,535 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 14:17:29,535 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 14:17:29,535 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 14:17:29,574 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 14:17:29,574 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 14:17:32,229 - __main__ - INFO - Created 499881 sequences of length 120
2025-09-11 14:17:32,230 - __main__ - INFO - Sequence shape: (499881, 120, 14)
2025-09-11 14:17:32,230 - __main__ - INFO - Target shape: (499881,)
2025-09-11 14:17:32,230 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 14:17:32,230 - __main__ - INFO - Final sequence shape: (499881, 120, 14)
2025-09-11 14:17:32,230 - __main__ - INFO - Final target shape: (499881,)
2025-09-11 14:17:32,233 - __main__ - INFO - Class distribution: [100000  99881 100000 100000 100000]
2025-09-11 14:17:32,234 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 14:17:33,057 - __main__ - INFO - Configured 7 GPU(s) with memory growth
2025-09-11 14:17:33,057 - __main__ - INFO - Starting LSTM model training...
2025-09-11 14:17:46,227 - __main__ - INFO - Training samples: 399904
2025-09-11 14:17:46,227 - __main__ - INFO - Validation samples: 99977
2025-09-11 14:17:48,860 - __main__ - ERROR - Training pipeline failed: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 14:17:48,861 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 595, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 514, in train
    self.model = build_lstm_model(self.config)
                 ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 402, in build_lstm_model
    return builder.build_model()
           ~~~~~~~~~~~~~~~~~~~^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 179, in build_model
    self._add_lstm_layers(model)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 215, in _add_lstm_layers
    lstm_layer = LSTM(
        units=self.config.lstm_units,
    ...<4 lines>...
        name=f"lstm_layer_{layer_idx + 1}"
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 476, in __init__
    cell = LSTMCell(
        units,
    ...<19 lines>...
        implementation=kwargs.pop("implementation", 2),
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 141, in __init__
    self.seed_generator = backend.random.SeedGenerator(seed=seed)
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 87, in __init__
    self.state = self.backend.Variable(
                 ~~~~~~~~~~~~~~~~~~~~~^
        seed_initializer,
        ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        name="seed_generator_state",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/common/variables.py", line 206, in __init__
    self._initialize_with_initializer(initializer)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in _initialize_with_initializer
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 42, in _initialize
    self._value = tf.Variable(
                  ~~~~~~~~~~~^
        value,
        ^^^^^^
    ...<4 lines>...
        synchronization=self._map_synchronization(self.synchronization),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in <lambda>
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
                             ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 84, in seed_initializer
    return self.backend.convert_to_tensor([seed, 0], dtype=dtype)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 151, in convert_to_tensor
    x = tf.convert_to_tensor(x)
RuntimeError: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 14:18:33,605 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:18:33,605 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 14 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,501

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2

Monitoring:
  - Metrics: accuracy, precision, recall
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:18:33,605 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 14:18:34,503 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 14:18:34,503 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 14:18:34,503 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 14:18:34,503 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 14:18:34,541 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 14:18:34,541 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 14:18:37,242 - __main__ - INFO - Created 499881 sequences of length 120
2025-09-11 14:18:37,242 - __main__ - INFO - Sequence shape: (499881, 120, 14)
2025-09-11 14:18:37,242 - __main__ - INFO - Target shape: (499881,)
2025-09-11 14:18:37,242 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 14:18:37,242 - __main__ - INFO - Final sequence shape: (499881, 120, 14)
2025-09-11 14:18:37,242 - __main__ - INFO - Final target shape: (499881,)
2025-09-11 14:18:37,245 - __main__ - INFO - Class distribution: [100000  99881 100000 100000 100000]
2025-09-11 14:18:37,246 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 14:18:37,344 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 14:18:37,344 - __main__ - INFO - Starting LSTM model training...
2025-09-11 14:18:40,358 - __main__ - INFO - Training samples: 399904
2025-09-11 14:18:40,358 - __main__ - INFO - Validation samples: 99977
2025-09-11 14:18:40,563 - __main__ - INFO - Model built successfully
2025-09-11 14:18:40,571 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 120, 32)             │           6,016 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 120, 32)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 120, 32)             │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 32)                  │           8,320 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 32)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 32)                  │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │             165 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 14,629 (57.14 KB)
 Trainable params: 14,629 (57.14 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 14:18:40,572 - __main__ - INFO - Beginning training process...
2025-09-11 14:19:52,848 - __main__ - ERROR - Training pipeline failed: Dimensions must be equal, but are 16 and 80 for '{{node LogicalAnd_1}} = LogicalAnd[](Tile_2, Greater)' with input shapes: [1,16], [1,80].
2025-09-11 14:19:52,848 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 595, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 526, in train
    self.history = self.model.fit(
                   ~~~~~~~~~~~~~~^
        X_train, y_train,
        ^^^^^^^^^^^^^^^^^
    ...<5 lines>...
        shuffle=True
        ^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py", line 1737, in logical_and
    return tf.logical_and(x1, x2)
           ~~~~~~~~~~~~~~^^^^^^^^
ValueError: Dimensions must be equal, but are 16 and 80 for '{{node LogicalAnd_1}} = LogicalAnd[](Tile_2, Greater)' with input shapes: [1,16], [1,80].
2025-09-11 14:22:19,451 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:22:19,452 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 14 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,501

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2

Monitoring:
  - Metrics: accuracy
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:22:19,452 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 14:22:20,289 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 14:22:20,289 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 14:22:20,289 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 14:22:20,289 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 14:22:20,326 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 14:22:20,326 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 14:22:22,359 - __main__ - INFO - Created 499881 sequences of length 120
2025-09-11 14:22:22,359 - __main__ - INFO - Sequence shape: (499881, 120, 14)
2025-09-11 14:22:22,359 - __main__ - INFO - Target shape: (499881,)
2025-09-11 14:22:22,359 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 14:22:22,360 - __main__ - INFO - Final sequence shape: (499881, 120, 14)
2025-09-11 14:22:22,360 - __main__ - INFO - Final target shape: (499881,)
2025-09-11 14:22:22,362 - __main__ - INFO - Class distribution: [100000  99881 100000 100000 100000]
2025-09-11 14:22:22,363 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 14:22:22,471 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 14:22:22,472 - __main__ - INFO - Starting LSTM model training...
2025-09-11 14:22:24,055 - __main__ - INFO - Training samples: 399904
2025-09-11 14:22:24,055 - __main__ - INFO - Validation samples: 99977
2025-09-11 14:22:24,220 - __main__ - INFO - Model built successfully
2025-09-11 14:22:24,225 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 120, 32)             │           6,016 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 120, 32)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 120, 32)             │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 32)                  │           8,320 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 32)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 32)                  │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │             165 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 14,629 (57.14 KB)
 Trainable params: 14,629 (57.14 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 14:22:24,226 - __main__ - INFO - Beginning training process...
2025-09-11 14:43:18,323 - __main__ - INFO - Configuration loaded successfully
2025-09-11 14:43:18,324 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 120 time steps × 14 features
  - 2x LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~14,501

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 100
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 14:43:18,324 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 14:43:19,895 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 14:43:19,895 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 14:43:19,895 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 14:43:19,895 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 14:43:19,936 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 14:43:19,936 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 14:44:59,156 - __main__ - INFO - Created 499881 sequences of length 120
2025-09-11 14:44:59,157 - __main__ - INFO - Sequence shape: (499881, 120, 14)
2025-09-11 14:44:59,157 - __main__ - INFO - Target shape: (499881,)
2025-09-11 14:44:59,157 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 14:44:59,157 - __main__ - INFO - Final sequence shape: (499881, 120, 14)
2025-09-11 14:44:59,157 - __main__ - INFO - Final target shape: (499881,)
2025-09-11 14:44:59,160 - __main__ - INFO - Class distribution: [100000  99881 100000 100000 100000]
2025-09-11 14:44:59,161 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 14:44:59,252 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 14:44:59,252 - __main__ - INFO - Starting LSTM model training...
2025-09-11 14:48:13,990 - __main__ - INFO - Training samples: 399904
2025-09-11 14:48:13,990 - __main__ - INFO - Validation samples: 99977
2025-09-11 14:48:14,219 - __main__ - INFO - Model built successfully
2025-09-11 14:48:14,227 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 120, 32)             │           6,016 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 120, 32)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 120, 32)             │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 32)                  │           8,320 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 32)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 32)                  │              64 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │             165 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 14,629 (57.14 KB)
 Trainable params: 14,629 (57.14 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 14:48:14,228 - __main__ - INFO - Beginning training process...
2025-09-11 15:35:25,930 - __main__ - INFO - Training session started at 2025-09-11 15:35:25
2025-09-11 15:35:25,930 - __main__ - INFO - Session logs will be saved to: training_20250911_153525.log
2025-09-11 15:35:25,933 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:35:25,933 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:35:25,933 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:35:26,904 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:35:26,904 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:35:26,904 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:35:26,904 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:35:26,943 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:35:26,943 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:35:28,602 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:35:28,602 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:35:28,602 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:35:28,602 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:35:28,602 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:35:28,602 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:35:28,607 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:35:28,608 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:35:28,991 - __main__ - INFO - Configured 7 GPU(s) with memory growth
2025-09-11 15:35:28,991 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:35:30,136 - __main__ - INFO - Training samples: 399949
2025-09-11 15:35:30,136 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:35:33,148 - __main__ - ERROR - Training pipeline failed: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 15:35:33,148 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 528, in train
    self.model = build_lstm_model(self.config)
                 ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 423, in build_lstm_model
    return builder.build_model()
           ~~~~~~~~~~~~~~~~~~~^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 183, in build_model
    self._add_lstm_layers(model)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 219, in _add_lstm_layers
    lstm_layer = LSTM(
        units=self.config.lstm_units,
    ...<4 lines>...
        name=f"lstm_layer_{layer_idx + 1}"
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 476, in __init__
    cell = LSTMCell(
        units,
    ...<19 lines>...
        implementation=kwargs.pop("implementation", 2),
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 141, in __init__
    self.seed_generator = backend.random.SeedGenerator(seed=seed)
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 87, in __init__
    self.state = self.backend.Variable(
                 ~~~~~~~~~~~~~~~~~~~~~^
        seed_initializer,
        ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        name="seed_generator_state",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/common/variables.py", line 206, in __init__
    self._initialize_with_initializer(initializer)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in _initialize_with_initializer
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 42, in _initialize
    self._value = tf.Variable(
                  ~~~~~~~~~~~^
        value,
        ^^^^^^
    ...<4 lines>...
        synchronization=self._map_synchronization(self.synchronization),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in <lambda>
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
                             ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 84, in seed_initializer
    return self.backend.convert_to_tensor([seed, 0], dtype=dtype)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 151, in convert_to_tensor
    x = tf.convert_to_tensor(x)
RuntimeError: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 15:36:39,905 - __main__ - INFO - Training session started at 2025-09-11 15:36:39
2025-09-11 15:36:39,905 - __main__ - INFO - Session logs will be saved to: training_20250911_153639.log
2025-09-11 15:36:39,908 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:36:39,908 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:36:39,908 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:36:40,809 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:36:40,810 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:36:40,810 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:36:40,810 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:36:40,847 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:36:40,848 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:36:42,126 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:36:42,127 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:36:42,127 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:36:42,127 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:36:42,127 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:36:42,127 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:36:42,129 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:36:42,130 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:36:42,228 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 15:36:42,228 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:36:43,299 - __main__ - INFO - Training samples: 399949
2025-09-11 15:36:43,299 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:36:43,453 - __main__ - INFO - Model built successfully
2025-09-11 15:36:43,459 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 15:36:43,460 - __main__ - INFO - Beginning training process...
2025-09-11 15:36:47,165 - __main__ - ERROR - Training pipeline failed: FBetaScore expects 2D inputs with shape (batch_size, output_dim). Received input shapes: y_pred.shape=(None, 5) and y_true.shape=(None,).
2025-09-11 15:36:47,165 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 540, in train
    self.history = self.model.fit(
                   ~~~~~~~~~~~~~~^
        X_train, y_train,
        ^^^^^^^^^^^^^^^^^
    ...<5 lines>...
        shuffle=True
        ^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/f_score_metrics.py", line 124, in _build
    raise ValueError(
    ...<4 lines>...
    )
ValueError: FBetaScore expects 2D inputs with shape (batch_size, output_dim). Received input shapes: y_pred.shape=(None, 5) and y_true.shape=(None,).
2025-09-11 15:37:53,408 - __main__ - INFO - Training session started at 2025-09-11 15:37:53
2025-09-11 15:37:53,408 - __main__ - INFO - Session logs will be saved to: training_20250911_153753.log
2025-09-11 15:37:53,410 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:37:53,411 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:37:53,411 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:37:54,293 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:37:54,293 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:37:54,293 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:37:54,293 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:37:54,331 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:37:54,331 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:37:55,628 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:37:55,628 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:37:55,629 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:37:55,629 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:37:55,629 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:37:55,629 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:37:55,631 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:37:55,632 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:37:55,734 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 15:37:55,734 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:37:56,811 - __main__ - INFO - Training samples: 399949
2025-09-11 15:37:56,811 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:37:56,973 - __main__ - INFO - Model built successfully
2025-09-11 15:37:56,980 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 15:37:56,980 - __main__ - INFO - Beginning training process...
2025-09-11 15:38:02,815 - __main__ - ERROR - Training pipeline failed: Graph execution error:

Detected at node LogicalAnd_4 defined at (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 657, in <module>

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 540, in train

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 114, in one_step_on_data

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 85, in train_step

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/trainer.py", line 490, in compute_metrics

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/compile_utils.py", line 334, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/compile_utils.py", line 21, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/confusion_metrics.py", line 522, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/metrics_utils.py", line 595, in update_confusion_matrix_variables

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/metrics_utils.py", line 568, in weighted_assign_add

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/ops/numpy.py", line 4011, in logical_and

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py", line 1737, in logical_and

Incompatible shapes: [1,80] vs. [1,16]
	 [[{{node LogicalAnd_4}}]] [Op:__inference_multi_step_on_iterator_5641]
2025-09-11 15:38:02,815 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 540, in train
    self.history = self.model.fit(
                   ~~~~~~~~~~~~~~^
        X_train, y_train,
        ^^^^^^^^^^^^^^^^^
    ...<5 lines>...
        shuffle=True
        ^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node LogicalAnd_4 defined at (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 657, in <module>

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 540, in train

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 114, in one_step_on_data

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 85, in train_step

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/trainer.py", line 490, in compute_metrics

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/compile_utils.py", line 334, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/trainers/compile_utils.py", line 21, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/confusion_metrics.py", line 522, in update_state

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/metrics_utils.py", line 595, in update_confusion_matrix_variables

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/metrics/metrics_utils.py", line 568, in weighted_assign_add

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/ops/numpy.py", line 4011, in logical_and

  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py", line 1737, in logical_and

Incompatible shapes: [1,80] vs. [1,16]
	 [[{{node LogicalAnd_4}}]] [Op:__inference_multi_step_on_iterator_5641]
2025-09-11 15:39:27,886 - __main__ - INFO - Training session started at 2025-09-11 15:39:27
2025-09-11 15:39:27,886 - __main__ - INFO - Session logs will be saved to: training_20250911_153927.log
2025-09-11 15:39:27,890 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:39:27,890 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:39:27,890 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:39:28,745 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:39:28,745 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:39:28,745 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:39:28,745 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:39:28,783 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:39:28,783 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:39:30,043 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:39:30,043 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:39:30,043 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:39:30,043 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:39:30,043 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:39:30,043 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:39:30,046 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:39:30,047 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:39:30,152 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 15:39:30,152 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:39:30,982 - __main__ - INFO - Training samples: 399949
2025-09-11 15:39:30,983 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:39:31,176 - __main__ - INFO - Model built successfully
2025-09-11 15:39:31,182 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓
┃ Layer (type)              ┃ Output Shape        ┃    Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)       │ (None, 64, 16)      │      1,984 │
├───────────────────────────┼─────────────────────┼────────────┤
│ dropout_1 (Dropout)       │ (None, 64, 16)      │          0 │
├───────────────────────────┼─────────────────────┼────────────┤
│ layer_norm_1              │ (None, 64, 16)      │         32 │
│ (LayerNormalization)      │                     │            │
├───────────────────────────┼─────────────────────┼────────────┤
│ lstm_layer_2 (LSTM)       │ (None, 16)          │      2,112 │
├───────────────────────────┼─────────────────────┼────────────┤
│ dropout_2 (Dropout)       │ (None, 16)          │          0 │
├───────────────────────────┼─────────────────────┼────────────┤
│ layer_norm_2              │ (None, 16)          │         32 │
│ (LayerNormalization)      │                     │            │
├───────────────────────────┼─────────────────────┼────────────┤
│ classification_output     │ (None, 5)           │         85 │
│ (Dense)                   │                     │            │
└───────────────────────────┴─────────────────────┴────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 15:39:31,182 - __main__ - INFO - Beginning training process...
2025-09-11 15:41:58,259 - __main__ - INFO - Training session started at 2025-09-11 15:41:58
2025-09-11 15:41:58,259 - __main__ - INFO - Session logs will be saved to: training_20250911_154158.log
2025-09-11 15:41:58,264 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:41:58,264 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:41:58,264 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:41:59,276 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:41:59,277 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:41:59,277 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:41:59,277 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:41:59,316 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:41:59,317 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:42:00,710 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:42:00,710 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:42:00,711 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:42:00,711 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:42:00,711 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:42:00,711 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:42:00,715 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:42:00,717 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:42:00,840 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 15:42:00,840 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:42:02,150 - __main__ - INFO - Training samples: 399949
2025-09-11 15:42:02,150 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:42:02,315 - __main__ - INFO - Model built successfully
2025-09-11 15:42:02,321 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 15:42:02,322 - __main__ - INFO - Beginning training process...
2025-09-11 15:49:39,750 - __main__ - INFO - Training session started at 2025-09-11 15:49:39
2025-09-11 15:49:39,750 - __main__ - INFO - Session logs will be saved to: training_20250911_154939.log
2025-09-11 15:49:39,753 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:49:39,753 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:49:39,753 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:49:40,753 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:49:40,753 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:49:40,754 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:49:40,754 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:49:40,790 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:49:40,791 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:49:42,128 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:49:42,128 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:49:42,128 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:49:42,128 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:49:42,128 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:49:42,128 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:49:42,131 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:49:42,132 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:49:42,239 - __main__ - INFO - No GPUs detected, using CPU
2025-09-11 15:49:42,239 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:49:43,457 - __main__ - INFO - Training samples: 399949
2025-09-11 15:49:43,457 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:49:43,620 - __main__ - INFO - Model built successfully
2025-09-11 15:49:43,626 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)             │ (None, 64, 16)         │         1,984 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 64, 16)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ layer_norm_1                    │ (None, 64, 16)         │            32 │
│ (LayerNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_layer_2 (LSTM)             │ (None, 16)             │         2,112 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_2 (Dropout)             │ (None, 16)             │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ layer_norm_2                    │ (None, 16)             │            32 │
│ (LayerNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ classification_output (Dense)   │ (None, 5)              │            85 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 15:49:43,627 - __main__ - INFO - Beginning training process...
2025-09-11 16:03:35,928 - __main__ - INFO - Training session started at 2025-09-11 16:03:35
2025-09-11 16:03:35,928 - __main__ - INFO - Session logs will be saved to: training_20250911_160335.log
2025-09-11 16:03:35,931 - __main__ - INFO - Configuration loaded successfully
2025-09-11 16:03:35,931 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 16:03:35,931 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 16:03:36,879 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 16:03:36,880 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 16:03:36,880 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 16:03:36,880 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 16:03:36,918 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 16:03:36,918 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 16:03:38,705 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 16:03:38,706 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 16:03:38,706 - __main__ - INFO - Target shape: (499937,)
2025-09-11 16:03:38,706 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 16:03:38,706 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 16:03:38,706 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 16:03:38,709 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 16:03:38,709 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 16:03:39,031 - __main__ - INFO - Configured 7 GPU(s) with memory growth
2025-09-11 16:03:39,032 - __main__ - INFO - Starting LSTM model training...
2025-09-11 16:03:40,483 - __main__ - INFO - Training samples: 399949
2025-09-11 16:03:40,484 - __main__ - INFO - Validation samples: 99988
2025-09-11 16:03:43,545 - __main__ - ERROR - Training pipeline failed: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 16:03:43,545 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 528, in train
    self.model = build_lstm_model(self.config)
                 ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 421, in build_lstm_model
    return builder.build_model()
           ~~~~~~~~~~~~~~~~~~~^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 183, in build_model
    self._add_lstm_layers(model)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 219, in _add_lstm_layers
    lstm_layer = LSTM(
        units=self.config.lstm_units,
    ...<4 lines>...
        name=f"lstm_layer_{layer_idx + 1}"
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 476, in __init__
    cell = LSTMCell(
        units,
    ...<19 lines>...
        implementation=kwargs.pop("implementation", 2),
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 141, in __init__
    self.seed_generator = backend.random.SeedGenerator(seed=seed)
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 87, in __init__
    self.state = self.backend.Variable(
                 ~~~~~~~~~~~~~~~~~~~~~^
        seed_initializer,
        ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        name="seed_generator_state",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/common/variables.py", line 206, in __init__
    self._initialize_with_initializer(initializer)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in _initialize_with_initializer
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 42, in _initialize
    self._value = tf.Variable(
                  ~~~~~~~~~~~^
        value,
        ^^^^^^
    ...<4 lines>...
        synchronization=self._map_synchronization(self.synchronization),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in <lambda>
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
                             ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 84, in seed_initializer
    return self.backend.convert_to_tensor([seed, 0], dtype=dtype)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 151, in convert_to_tensor
    x = tf.convert_to_tensor(x)
RuntimeError: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 16:06:33,716 - __main__ - INFO - Training session started at 2025-09-11 16:06:33
2025-09-11 16:06:33,717 - __main__ - INFO - Session logs will be saved to: training_20250911_160633.log
2025-09-11 16:06:33,724 - __main__ - INFO - Configuration loaded successfully
2025-09-11 16:06:33,724 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 16:06:33,724 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 16:06:34,889 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 16:06:34,889 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 16:06:34,889 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 16:06:34,889 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 16:06:34,927 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 16:06:34,928 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 16:06:36,574 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 16:06:36,574 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 16:06:36,574 - __main__ - INFO - Target shape: (499937,)
2025-09-11 16:06:36,574 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 16:06:36,575 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 16:06:36,575 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 16:06:36,578 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 16:06:36,578 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 16:06:36,675 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-11 16:06:36,691 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-11 16:06:36,692 - __main__ - INFO - Starting LSTM model training...
2025-09-11 16:06:37,810 - __main__ - INFO - Training samples: 399949
2025-09-11 16:06:37,810 - __main__ - INFO - Validation samples: 99988
2025-09-11 16:06:37,953 - __main__ - INFO - Model built successfully
2025-09-11 16:06:37,959 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 16:06:37,960 - __main__ - INFO - Beginning training process...
2025-09-11 17:15:28,584 - __main__ - INFO - Training completed successfully
2025-09-11 17:15:28,585 - __main__ - INFO - final_train_loss: 0.0665
2025-09-11 17:15:28,585 - __main__ - INFO - final_val_loss: 0.0635
2025-09-11 17:15:28,585 - __main__ - INFO - best_val_loss: 0.0635
2025-09-11 17:15:28,585 - __main__ - INFO - total_epochs: 4.0000
2025-09-11 17:15:28,585 - __main__ - INFO - final_train_accuracy: 0.9750
2025-09-11 17:15:28,585 - __main__ - INFO - final_val_accuracy: 0.9737
2025-09-11 17:15:28,585 - __main__ - INFO - best_val_accuracy: 0.9749
2025-09-11 17:15:28,585 - __main__ - INFO - Training session completed at 2025-09-11 17:15:28
2025-09-11 17:15:28,585 - __main__ - INFO - Timestamped log saved as: training_20250911_160633.log
2025-09-11 17:15:28,585 - __main__ - INFO - CSV metrics saved as: training_metrics_20250911_160633.csv
2025-09-11 17:15:28,629 - __main__ - INFO - Final model saved to: models/saved_Models/experiment1_final.keras
2025-09-11 17:15:28,629 - __main__ - INFO - Training pipeline completed successfully!
2025-09-11 19:58:05,158 - __main__ - INFO - Training session started at 2025-09-11 19:58:05
2025-09-11 19:58:05,158 - __main__ - INFO - Session logs will be saved to: training_20250911_195805.log
2025-09-11 19:58:05,162 - __main__ - INFO - Configuration loaded successfully
2025-09-11 19:58:05,162 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 19:58:05,162 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 19:58:09,477 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 19:58:09,477 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 19:58:09,478 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 19:58:09,478 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 19:58:23,640 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 19:58:23,641 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 20:01:35,464 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 20:01:35,464 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 20:01:35,464 - __main__ - INFO - Target shape: (499937,)
2025-09-11 20:01:35,464 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 20:01:35,464 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 20:01:35,464 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 20:01:35,468 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 20:01:35,495 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 20:01:35,631 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-11 20:01:35,741 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-11 20:01:35,741 - __main__ - INFO - Starting LSTM model training...
2025-09-11 20:04:20,680 - __main__ - INFO - Training samples: 399949
2025-09-11 20:04:20,680 - __main__ - INFO - Validation samples: 99988
2025-09-11 20:04:20,984 - __main__ - INFO - Model built successfully
2025-09-11 20:04:20,991 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 20:04:20,992 - __main__ - INFO - Beginning training process...
2025-09-11 21:46:12,371 - __main__ - INFO - Training completed successfully
2025-09-11 21:46:12,390 - __main__ - INFO - final_train_loss: 0.0665
2025-09-11 21:46:12,390 - __main__ - INFO - final_val_loss: 0.0681
2025-09-11 21:46:12,390 - __main__ - INFO - best_val_loss: 0.0631
2025-09-11 21:46:12,390 - __main__ - INFO - total_epochs: 4.0000
2025-09-11 21:46:12,390 - __main__ - INFO - final_train_accuracy: 0.9750
2025-09-11 21:46:12,390 - __main__ - INFO - final_val_accuracy: 0.9758
2025-09-11 21:46:12,390 - __main__ - INFO - best_val_accuracy: 0.9767
2025-09-11 21:46:12,391 - __main__ - INFO - Training session completed at 2025-09-11 21:46:12
2025-09-11 21:46:12,391 - __main__ - INFO - Timestamped log saved as: training_20250911_195805.log
2025-09-11 21:46:12,391 - __main__ - INFO - CSV metrics saved as: training_metrics_20250911_195805.csv
2025-09-11 21:46:12,883 - __main__ - INFO - Final model saved to: models/saved_Models/experiment1_final.keras
2025-09-11 21:46:12,891 - __main__ - INFO - Training pipeline completed successfully!
2025-09-11 22:04:09,081 - __main__ - INFO - Training session started at 2025-09-11 22:04:09
2025-09-11 22:04:09,081 - __main__ - INFO - Session logs will be saved to: training_20250911_220409.log
2025-09-11 22:04:09,084 - __main__ - INFO - Configuration loaded successfully
2025-09-11 22:04:09,084 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.2
  - Validation split: 0.2
  - Early stopping patience: 4

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment2.keras
2025-09-11 22:04:09,084 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 22:04:13,933 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 22:04:13,934 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 22:04:13,934 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 22:04:13,934 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 22:04:18,225 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 22:04:18,226 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 22:05:55,674 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 22:05:55,674 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 22:05:55,674 - __main__ - INFO - Target shape: (499937,)
2025-09-11 22:05:55,675 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 22:05:55,675 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 22:05:55,675 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 22:05:55,678 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 22:05:55,681 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 22:05:55,782 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-11 22:05:55,793 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-11 22:05:55,793 - __main__ - INFO - Starting LSTM model training...
2025-09-11 22:07:16,093 - __main__ - INFO - Training samples: 399949
2025-09-11 22:07:16,094 - __main__ - INFO - Validation samples: 99988
2025-09-11 22:07:16,439 - __main__ - INFO - Model built successfully
2025-09-11 22:07:16,458 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,245 (16.58 KB)
 Trainable params: 4,245 (16.58 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-11 22:07:16,470 - __main__ - INFO - Beginning training process...
2025-09-12 02:18:47,553 - __main__ - INFO - Training completed successfully
2025-09-12 02:18:47,554 - __main__ - INFO - final_train_loss: 0.0582
2025-09-12 02:18:47,555 - __main__ - INFO - final_val_loss: 0.0548
2025-09-12 02:18:47,555 - __main__ - INFO - best_val_loss: 0.0548
2025-09-12 02:18:47,555 - __main__ - INFO - total_epochs: 15.0000
2025-09-12 02:18:47,555 - __main__ - INFO - final_train_accuracy: 0.9780
2025-09-12 02:18:47,555 - __main__ - INFO - final_val_accuracy: 0.9792
2025-09-12 02:18:47,555 - __main__ - INFO - best_val_accuracy: 0.9792
2025-09-12 02:18:47,555 - __main__ - INFO - Training session completed at 2025-09-12 02:18:47
2025-09-12 02:18:47,555 - __main__ - INFO - Timestamped log saved as: training_20250911_220409.log
2025-09-12 02:18:47,555 - __main__ - INFO - CSV metrics saved as: training_metrics_20250911_220409.csv
2025-09-12 02:18:47,791 - __main__ - INFO - Final model saved to: models/saved_Models/experiment2_final.keras
2025-09-12 02:18:47,791 - __main__ - INFO - Training pipeline completed successfully!
2025-09-12 12:46:09,320 - __main__ - INFO - Training session started at 2025-09-12 12:46:09
2025-09-12 12:46:09,320 - __main__ - INFO - Session logs will be saved to: training_20250912_124609.log
2025-09-12 12:46:09,325 - __main__ - INFO - Configuration loaded successfully
2025-09-12 12:46:09,325 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps × 14 features
  - 3x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~6,293

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.2
  - Validation split: 0.2
  - Early stopping patience: 3

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment3.keras
2025-09-12 12:46:09,325 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-12 12:46:13,470 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-12 12:46:13,471 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-12 12:46:13,471 - __main__ - INFO - Target: label_stage_encoded
2025-09-12 12:46:13,471 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-12 12:46:22,776 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-12 12:46:22,777 - __main__ - INFO - Target vector shape: (500000,)
2025-09-12 12:47:54,854 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-12 12:47:54,855 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-12 12:47:54,855 - __main__ - INFO - Target shape: (499937,)
2025-09-12 12:47:54,855 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-12 12:47:54,855 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-12 12:47:54,855 - __main__ - INFO - Final target shape: (499937,)
2025-09-12 12:47:54,858 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-12 12:47:54,861 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-12 12:47:54,962 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-12 12:47:54,971 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-12 12:47:54,971 - __main__ - INFO - Starting LSTM model training...
2025-09-12 12:49:06,418 - __main__ - INFO - Training samples: 399949
2025-09-12 12:49:06,419 - __main__ - INFO - Validation samples: 99988
2025-09-12 12:49:06,632 - __main__ - INFO - Model built successfully
2025-09-12 12:49:06,639 - __main__ - INFO - Model: "LSTM_Classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_layer_1 (LSTM)                  │ (None, 64, 16)              │           1,984 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_1 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_2 (LSTM)                  │ (None, 64, 16)              │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 64, 16)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_2 (LayerNormalization)    │ (None, 64, 16)              │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_layer_3 (LSTM)                  │ (None, 16)                  │           2,112 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_3 (Dropout)                  │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ layer_norm_3 (LayerNormalization)    │ (None, 16)                  │              32 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ classification_output (Dense)        │ (None, 5)                   │              85 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 6,389 (24.96 KB)
 Trainable params: 6,389 (24.96 KB)
 Non-trainable params: 0 (0.00 B)

2025-09-12 12:49:06,640 - __main__ - INFO - Beginning training process...
2025-09-12 18:12:06,950 - __main__ - INFO - Training completed successfully
2025-09-12 18:12:06,952 - __main__ - INFO - final_train_loss: 0.0611
2025-09-12 18:12:06,952 - __main__ - INFO - final_val_loss: 0.0585
2025-09-12 18:12:06,952 - __main__ - INFO - best_val_loss: 0.0577
2025-09-12 18:12:06,952 - __main__ - INFO - total_epochs: 8.0000
2025-09-12 18:12:06,952 - __main__ - INFO - final_train_accuracy: 0.9779
2025-09-12 18:12:06,952 - __main__ - INFO - final_val_accuracy: 0.9770
2025-09-12 18:12:06,952 - __main__ - INFO - best_val_accuracy: 0.9782
2025-09-12 18:12:06,952 - __main__ - INFO - Training session completed at 2025-09-12 18:12:06
2025-09-12 18:12:06,952 - __main__ - INFO - Timestamped log saved as: training_20250912_124609.log
2025-09-12 18:12:06,952 - __main__ - INFO - CSV metrics saved as: training_metrics_20250912_124609.csv
2025-09-12 18:12:07,240 - __main__ - INFO - Final model saved to: models/saved_Models/experiment3_final.keras
2025-09-12 18:12:07,240 - __main__ - INFO - Training pipeline completed successfully!
2025-09-14 10:00:54,820 - __main__ - INFO - Training session started at 2025-09-14 10:00:54
2025-09-14 10:00:54,821 - __main__ - INFO - Session logs will be saved to: training_20250914_100054.log
2025-09-14 10:00:54,833 - __main__ - INFO - Configuration loaded successfully
2025-09-14 10:00:54,833 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 128 time steps  14 features
  - 3x Bidirectional LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~62,021

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.2
  - Validation split: 0.2
  - Early stopping patience: 3

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models\saved_Models\experiment4.keras
2025-09-14 10:00:54,834 - __main__ - INFO - Loading data from C:\Users\dicla\Research_Internship_Under_Dr_Rakesh_Matam\Project_3\dataset\combined_dataset_short_balanced_encoded_normalised_shuffled.csv
2025-09-14 10:00:55,386 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-14 10:00:55,386 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-14 10:00:55,387 - __main__ - INFO - Target: label_stage_encoded
2025-09-14 10:00:55,387 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-14 10:00:55,422 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-14 10:00:55,422 - __main__ - INFO - Target vector shape: (500000,)
2025-09-14 10:00:57,179 - __main__ - INFO - Created 499873 sequences of length 128
2025-09-14 10:00:57,179 - __main__ - INFO - Sequence shape: (499873, 128, 14)
2025-09-14 10:00:57,179 - __main__ - INFO - Target shape: (499873,)
2025-09-14 10:00:57,180 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-14 10:00:57,180 - __main__ - INFO - Final sequence shape: (499873, 128, 14)
2025-09-14 10:00:57,180 - __main__ - INFO - Final target shape: (499873,)
2025-09-14 10:00:57,183 - __main__ - INFO - Class distribution: [99968 99975 99973 99974 99983]
2025-09-14 10:00:57,188 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-14 10:00:57,192 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-14 10:00:57,209 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-14 10:00:57,210 - __main__ - INFO - Starting LSTM model training...
2025-09-14 10:00:59,358 - __main__ - INFO - Training samples: 399898
2025-09-14 10:00:59,359 - __main__ - INFO - Validation samples: 99975
2025-09-14 10:01:00,020 - __main__ - INFO - Model built successfully
2025-09-14 10:01:00,108 - __main__ - INFO - Beginning training process...
2025-09-14 10:10:52,353 - __main__ - INFO - Training session started at 2025-09-14 10:10:52
2025-09-14 10:10:52,353 - __main__ - INFO - Session logs will be saved to: training_20250914_101052.log
2025-09-14 10:10:52,358 - __main__ - INFO - Configuration loaded successfully
2025-09-14 10:10:52,358 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 128 time steps  14 features
  - 3x Bidirectional LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~62,021

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.2
  - Validation split: 0.2
  - Early stopping patience: 3

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models\saved_Models\experiment4.keras
2025-09-14 10:10:52,358 - __main__ - INFO - Loading data from C:\Users\dicla\Research_Internship_Under_Dr_Rakesh_Matam\Project_3\dataset\combined_dataset_short_balanced_encoded_normalised_shuffled.csv
2025-09-14 10:10:52,818 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-14 10:10:52,818 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-14 10:10:52,818 - __main__ - INFO - Target: label_stage_encoded
2025-09-14 10:10:52,818 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-14 10:10:52,844 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-14 10:10:52,844 - __main__ - INFO - Target vector shape: (500000,)
2025-09-14 10:10:54,475 - __main__ - INFO - Created 499873 sequences of length 128
2025-09-14 10:10:54,475 - __main__ - INFO - Sequence shape: (499873, 128, 14)
2025-09-14 10:10:54,475 - __main__ - INFO - Target shape: (499873,)
2025-09-14 10:10:54,476 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-14 10:10:54,476 - __main__ - INFO - Final sequence shape: (499873, 128, 14)
2025-09-14 10:10:54,476 - __main__ - INFO - Final target shape: (499873,)
2025-09-14 10:10:54,478 - __main__ - INFO - Class distribution: [99968 99975 99973 99974 99983]
2025-09-14 10:10:54,482 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-14 10:10:54,485 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-14 10:10:54,491 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-14 10:10:54,492 - __main__ - INFO - Starting LSTM model training...
2025-09-14 10:10:57,281 - __main__ - INFO - Training samples: 399898
2025-09-14 10:10:57,287 - __main__ - INFO - Validation samples: 99975
2025-09-14 10:10:57,685 - __main__ - INFO - Model built successfully
2025-09-14 10:10:57,731 - __main__ - INFO - Beginning training process...
2025-09-14 13:39:54,951 - __main__ - INFO - Training session started at 2025-09-14 13:39:54
2025-09-14 13:39:54,952 - __main__ - INFO - Session logs will be saved to: training_20250914_133954.log
2025-09-14 13:39:54,957 - __main__ - INFO - Configuration loaded successfully
2025-09-14 13:39:54,957 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 128 time steps  14 features
  - 3x Bidirectional LSTM layers (32 units each)
  - Output: 5 classes
  - Estimated parameters: ~62,021

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.2
  - Validation split: 0.2
  - Early stopping patience: 3

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models\saved_Models\experiment4.keras
2025-09-14 13:39:54,957 - __main__ - INFO - Loading data from C:\Users\dicla\Research_Internship_Under_Dr_Rakesh_Matam\Project_3\dataset\combined_dataset_short_balanced_encoded_normalised.csv
2025-09-14 13:39:55,445 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-14 13:39:55,446 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-14 13:39:55,446 - __main__ - INFO - Target: label_stage_encoded
2025-09-14 13:39:55,446 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-14 13:39:55,479 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-14 13:39:55,479 - __main__ - INFO - Target vector shape: (500000,)
2025-09-14 13:39:57,182 - __main__ - INFO - Created 499873 sequences of length 128
2025-09-14 13:39:57,183 - __main__ - INFO - Sequence shape: (499873, 128, 14)
2025-09-14 13:39:57,183 - __main__ - INFO - Target shape: (499873,)
2025-09-14 13:39:57,183 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-14 13:39:57,183 - __main__ - INFO - Final sequence shape: (499873, 128, 14)
2025-09-14 13:39:57,183 - __main__ - INFO - Final target shape: (499873,)
2025-09-14 13:39:57,187 - __main__ - INFO - Class distribution: [100000  99873 100000 100000 100000]
2025-09-14 13:39:57,193 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-14 13:39:57,200 - __main__ - INFO - No GPUs detected - using CPU only
2025-09-14 13:39:57,221 - __main__ - INFO - TensorFlow configured for CPU usage. Test tensor device: /job:localhost/replica:0/task:0/device:CPU:0
2025-09-14 13:39:57,222 - __main__ - INFO - Starting LSTM model training...
2025-09-14 13:40:04,491 - __main__ - INFO - Training samples: 399898
2025-09-14 13:40:04,501 - __main__ - INFO - Validation samples: 99975
2025-09-14 13:40:05,026 - __main__ - INFO - Model built successfully
2025-09-14 13:40:05,100 - __main__ - INFO - Beginning training process...
