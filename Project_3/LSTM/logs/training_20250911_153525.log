2025-09-11 15:35:25,930 - __main__ - INFO - Training session started at 2025-09-11 15:35:25
2025-09-11 15:35:25,930 - __main__ - INFO - Session logs will be saved to: training_20250911_153525.log
2025-09-11 15:35:25,933 - __main__ - INFO - Configuration loaded successfully
2025-09-11 15:35:25,933 - __main__ - INFO - Model configuration:
LSTM Model Configuration Summary:
================================
Architecture:
  - Input: 64 time steps Ã— 14 features
  - 2x LSTM layers (16 units each)
  - Output: 5 classes
  - Estimated parameters: ~4,181

Training Setup:
  - Learning rate: 0.001
  - Batch size: 16
  - Max epochs: 15
  - Dropout: 0.3
  - Validation split: 0.2
  - Early stopping patience: 2

Monitoring:
  - Metrics: accuracy, val_loss, precision, recall, f1_score
  - Model save path: models/saved_Models/experiment1.keras
2025-09-11 15:35:25,933 - __main__ - INFO - Loading data from /fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/dataset/combined_dataset_short_balanced_encoded_normalised.csv
2025-09-11 15:35:26,904 - __main__ - INFO - Data loaded successfully: (500000, 15)
2025-09-11 15:35:26,904 - __main__ - INFO - Features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']
2025-09-11 15:35:26,904 - __main__ - INFO - Target: label_stage_encoded
2025-09-11 15:35:26,904 - __main__ - INFO - Preparing preprocessed data for LSTM training...
2025-09-11 15:35:26,943 - __main__ - INFO - Feature matrix shape: (500000, 14)
2025-09-11 15:35:26,943 - __main__ - INFO - Target vector shape: (500000,)
2025-09-11 15:35:28,602 - __main__ - INFO - Created 499937 sequences of length 64
2025-09-11 15:35:28,602 - __main__ - INFO - Sequence shape: (499937, 64, 14)
2025-09-11 15:35:28,602 - __main__ - INFO - Target shape: (499937,)
2025-09-11 15:35:28,602 - __main__ - INFO - Preprocessed data preparation completed successfully
2025-09-11 15:35:28,602 - __main__ - INFO - Final sequence shape: (499937, 64, 14)
2025-09-11 15:35:28,602 - __main__ - INFO - Final target shape: (499937,)
2025-09-11 15:35:28,607 - __main__ - INFO - Class distribution: [100000  99937 100000 100000 100000]
2025-09-11 15:35:28,608 - __main__ - INFO - Random seeds set to 42 for reproducibility
2025-09-11 15:35:28,991 - __main__ - INFO - Configured 7 GPU(s) with memory growth
2025-09-11 15:35:28,991 - __main__ - INFO - Starting LSTM model training...
2025-09-11 15:35:30,136 - __main__ - INFO - Training samples: 399949
2025-09-11 15:35:30,136 - __main__ - INFO - Validation samples: 99988
2025-09-11 15:35:33,148 - __main__ - ERROR - Training pipeline failed: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
2025-09-11 15:35:33,148 - __main__ - ERROR - Full traceback:
Traceback (most recent call last):
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 637, in main
    model, history = trainer.train(X, y)
                     ~~~~~~~~~~~~~^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/scirpts/train.py", line 528, in train
    self.model = build_lstm_model(self.config)
                 ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 423, in build_lstm_model
    return builder.build_model()
           ~~~~~~~~~~~~~~~~~~~^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 183, in build_model
    self._add_lstm_layers(model)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/Project_3/LSTM/lstm/builder.py", line 219, in _add_lstm_layers
    lstm_layer = LSTM(
        units=self.config.lstm_units,
    ...<4 lines>...
        name=f"lstm_layer_{layer_idx + 1}"
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 476, in __init__
    cell = LSTMCell(
        units,
    ...<19 lines>...
        implementation=kwargs.pop("implementation", 2),
    )
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/lstm.py", line 141, in __init__
    self.seed_generator = backend.random.SeedGenerator(seed=seed)
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 87, in __init__
    self.state = self.backend.Variable(
                 ~~~~~~~~~~~~~~~~~~~~~^
        seed_initializer,
        ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        name="seed_generator_state",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/common/variables.py", line 206, in __init__
    self._initialize_with_initializer(initializer)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in _initialize_with_initializer
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 42, in _initialize
    self._value = tf.Variable(
                  ~~~~~~~~~~~^
        value,
        ^^^^^^
    ...<4 lines>...
        synchronization=self._map_synchronization(self.synchronization),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 52, in <lambda>
    self._initialize(lambda: initializer(self._shape, dtype=self._dtype))
                             ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/random/seed_generator.py", line 84, in seed_initializer
    return self.backend.convert_to_tensor([seed, 0], dtype=dtype)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/siddhant.gond22b@iiitg.ac.in/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/core.py", line 151, in convert_to_tensor
    x = tf.convert_to_tensor(x)
RuntimeError: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory
